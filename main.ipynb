{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps required:\n",
    "   1. for loop for each sentence on the txt document.\n",
    "   2. read the sentence.\n",
    "   3. wait the input sound for that sentence.\n",
    "   4. convert the sound to lyrics.\n",
    "   5. measure the similarity between the main sentence and the input.\n",
    "   6. save the results in the progress list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def iterate_arabic_sentences(file_path):\n",
    "    S = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        # Split the content into sentences using regular expressions\n",
    "        sentences = re.split(r'[.?!]', content)\n",
    "        # Filter out empty sentences\n",
    "        sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "        # Print each sentence\n",
    "        for sentence in sentences:\n",
    "            print(sentence)\n",
    "        return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "هيا بنا معا لنبدأ درسنا الاول\n",
      "ذهبت مع امى الى الحديقة\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sentences.txt' \n",
    "S = iterate_arabic_sentences(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second step: Read the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "def read_sentence(S):\n",
    "    counter = 1\n",
    "    for sentence in S:\n",
    "        sentences = sentence.split('\\n')\n",
    "        for s in sentences:\n",
    "            file_name = f\"text_{counter}.mp3\"  \n",
    "            obj = gTTS(text=s, lang='ar', slow=False)\n",
    "            obj.save(file_name)\n",
    "            print(s)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "هيا بنا معا لنبدأ درسنا الاول\n",
      "ذهبت مع امى الى الحديقة\n"
     ]
    }
   ],
   "source": [
    "read_sentence(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### third step: Convert sound input to lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def STL(file_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(file_path) as source:\n",
    "        audio = r.record(source)\n",
    "    t = r.recognize_google(audio, language='ar-AR')\n",
    "    print(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For loop for each .wav file and save the result in list called `input sound`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate for list for input audio paths\n",
    "audio_list_path = ['']\n",
    "Y = []\n",
    "for i in audio_list_path:\n",
    "    Y.append(STL(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = S\n",
    "Y = ['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def calculate_cosine_similarity(X, Y):\n",
    "    # tokenization\n",
    "    X_list = word_tokenize(X)\n",
    "    Y_list = word_tokenize(Y)\n",
    "\n",
    "    # sw contains the list of stopwords\n",
    "    sw = stopwords.words('arabic')\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "\n",
    "    # remove stop words from the strings\n",
    "    X_set = {w for w in X_list if not w in sw}\n",
    "    Y_set = {w for w in Y_list if not w in sw}\n",
    "\n",
    "    # form a set containing keywords of both strings\n",
    "    rvector = X_set.union(Y_set)\n",
    "    for w in rvector:\n",
    "        if w in X_set:\n",
    "            l1.append(1)  # create a vector\n",
    "        else:\n",
    "            l1.append(0)\n",
    "        if w in Y_set:\n",
    "            l2.append(1)\n",
    "        else:\n",
    "            l2.append(0)\n",
    "    c = 0\n",
    "\n",
    "    # cosine formula\n",
    "    for i in range(len(rvector)):\n",
    "        c += l1[i] * l2[i]\n",
    "    cosine = c / float((sum(l1) * sum(l2))**0.5)\n",
    "    return cosine\n",
    "\n",
    "\n",
    "def calculate_average_similarity(X_list, Y_list):\n",
    "    total_similarity = 0.0\n",
    "    num_pairs = min(len(X_list), len(Y_list))\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        X = X_list[i]\n",
    "        Y = Y_list[i]\n",
    "        similarity = calculate_cosine_similarity(X, Y)\n",
    "        total_similarity += similarity\n",
    "\n",
    "    average_similarity = total_similarity / num_pairs\n",
    "    return average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Similarity: 0.6666666666666666\n",
      "Average Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_list = [\"أهلاً وسهلاً\", \"كيف حالك؟\", \"أتمنى لك يومًا سعيدًا\"]\n",
    "Y_list = [\"أهلا وسهلا\", \"كيف حالك؟\",\"أتمنى لك يومًا سعيدًا\"]\n",
    "\n",
    "X = S\n",
    "Y = ['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']\n",
    "\n",
    "average_similarity = calculate_average_similarity(X_list, Y_list)\n",
    "print(\"Average Similarity:\", average_similarity)\n",
    "\n",
    "average_similarity = calculate_average_similarity(X, Y)\n",
    "print(\"Average Similarity:\", average_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
