{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps required:\n",
    "   1. for loop for each sentence on the txt document.\n",
    "   2. read the sentence.\n",
    "   3. wait the input sound for that sentence.\n",
    "   4. convert the sound to lyrics.\n",
    "   5. measure the similarity between the main sentence and the input.\n",
    "   6. save the results in the progress list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gtts import gTTS\n",
    "import speech_recognition as sr\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def iterate_arabic_sentences(file_path):\n",
    "    S = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        # Split the content into sentences using regular expressions\n",
    "        sentences = re.split(r'[.?!]', content)\n",
    "        # Filter out empty sentences\n",
    "        sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "        # Print each sentence\n",
    "        for sentence in sentences:\n",
    "            print(sentence)\n",
    "        return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "هيا بنا معا لنبدأ درسنا الاول\n",
      "ذهبت مع امى الى الحديقة\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Sentences.txt' \n",
    "S = iterate_arabic_sentences(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_english_sentences(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        # Split the content into sentences using regular expressions\n",
    "        sentences = re.split(r'[.?!]', content)\n",
    "        # Filter out empty sentences and return the sentences list\n",
    "        return [sentence.strip() for sentence in sentences if sentence.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's come together to start our first lesson\n",
      "We went to the park with my mother\n",
      "Today we learn how to make a candy bar\n",
      "Today I played ball with my friends and we had fun\n",
      "My brothers and I enjoy watching TV together\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Let's come together to start our first lesson\\nWe went to the park with my mother\\nToday we learn how to make a candy bar\\nToday I played ball with my friends and we had fun\\nMy brothers and I enjoy watching TV together\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'English_sentences.txt' \n",
    "S = iterate_arabic_sentences(file_path)\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second step: Read the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "def read_sentence(S):\n",
    "    counter = 1\n",
    "    for sentence in S:\n",
    "        sentences = sentence.split('\\n')\n",
    "        for s in sentences:\n",
    "            file_name = f\"text_{counter}.mp3\"  \n",
    "            obj = gTTS(text=s, lang='ar', slow=False)\n",
    "            obj.save(file_name)\n",
    "            print(s)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "هيا بنا معا لنبدأ درسنا الاول\n",
      "ذهبت مع امى الى الحديقة\n"
     ]
    }
   ],
   "source": [
    "read_sentence(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_English_sentence(S):\n",
    "    counter = 1\n",
    "    for sentence in S:\n",
    "        sentences = sentence.split('\\n')\n",
    "        for s in sentences:\n",
    "            file_name = f\"text_{counter}.mp3\"  \n",
    "            obj = gTTS(text=s,lang='en', slow=False)\n",
    "            obj.save(file_name)\n",
    "            print(s)\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's come together to start our first lesson\n",
      "We went to the park with my mother\n",
      "Today we learn how to make a candy bar\n",
      "Today I played ball with my friends and we had fun\n",
      "My brothers and I enjoy watching TV together\n"
     ]
    }
   ],
   "source": [
    "read_English_sentence(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### third step: Convert sound input to lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "def STL(folder_path):\n",
    "    r = sr.Recognizer()\n",
    "    transcriptions = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with sr.AudioFile(file_path) as source:\n",
    "                audio = r.record(source)\n",
    "            t = r.recognize_google(audio, language='ar-AR')\n",
    "            transcriptions.append(t)\n",
    "\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "s = STL(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['هيا بنا معا لنبدا درسنا الاولى',\n",
       " 'ذهبنا الى الحديقه مع امه',\n",
       " 'نتعلم اليوم كيف نصنع قالب حلوى',\n",
       " 'لعبت اليوم الكره مع اصدقاء وكنا مستمتعين باللعب',\n",
       " 'اخوته وانا نستمتع بمشاهده التلفاز مع بعضنا']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For loop for each .wav file and save the result in list called `input sound`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate for list for input audio paths\n",
    "audio_list_path = ['']\n",
    "Y = []\n",
    "for i in audio_list_path:\n",
    "    Y.append(STL(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = S\n",
    "Y = ['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def calculate_cosine_similarity(X, Y):\n",
    "    # tokenization\n",
    "    X_list = word_tokenize(X)\n",
    "    Y_list = word_tokenize(Y)\n",
    "\n",
    "    # sw contains the list of stopwords\n",
    "    sw = stopwords.words('arabic')\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "\n",
    "    # remove stop words from the strings\n",
    "    X_set = {w for w in X_list if not w in sw}\n",
    "    Y_set = {w for w in Y_list if not w in sw}\n",
    "\n",
    "    # form a set containing keywords of both strings\n",
    "    rvector = X_set.union(Y_set)\n",
    "    for w in rvector:\n",
    "        if w in X_set:\n",
    "            l1.append(1)  # create a vector\n",
    "        else:\n",
    "            l1.append(0)\n",
    "        if w in Y_set:\n",
    "            l2.append(1)\n",
    "        else:\n",
    "            l2.append(0)\n",
    "    c = 0\n",
    "\n",
    "    # cosine formula\n",
    "    for i in range(len(rvector)):\n",
    "        c += l1[i] * l2[i]\n",
    "    cosine = c / float((sum(l1) * sum(l2))**0.5)\n",
    "    return cosine\n",
    "\n",
    "\n",
    "def calculate_average_similarity(X_list, Y_list):\n",
    "    total_similarity = 0.0\n",
    "    num_pairs = min(len(X_list), len(Y_list))\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        X = X_list[i]\n",
    "        Y = Y_list[i]\n",
    "        similarity = calculate_cosine_similarity(X, Y)\n",
    "        total_similarity += similarity\n",
    "\n",
    "    average_similarity = total_similarity / num_pairs\n",
    "    return average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Similarity: 0.6666666666666666\n",
      "Average Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_list = [\"أهلاً وسهلاً\", \"كيف حالك؟\", \"أتمنى لك يومًا سعيدًا\"]\n",
    "Y_list = [\"أهلا وسهلا\", \"كيف حالك؟\",\"أتمنى لك يومًا سعيدًا\"]\n",
    "\n",
    "X = S\n",
    "Y = ['هيا بنا معا لنبدأ درسنا الاول\\nذهبت مع امى الى الحديقة']\n",
    "\n",
    "average_similarity = calculate_average_similarity(X_list, Y_list)\n",
    "print(\"Average Similarity:\", average_similarity)\n",
    "\n",
    "average_similarity = calculate_average_similarity(X, Y)\n",
    "print(\"Average Similarity:\", average_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
